{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F454zhY-Xd8f",
        "outputId": "ef8f488e-2c03-4c51-b7e8-c5900bb41c25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts per class: [[15  0  0]\n",
            " [10  0  0]\n",
            " [ 2  0  0]\n",
            " [ 3  0  0]\n",
            " [10  0  0]\n",
            " [10  0  0]\n",
            " [ 4  0  0]\n",
            " [14  0  0]\n",
            " [ 1  0  1]\n",
            " [ 6  0  0]\n",
            " [ 9  0  0]\n",
            " [ 1  0  0]\n",
            " [ 6  0  0]\n",
            " [ 2  0  0]\n",
            " [ 7  0  0]\n",
            " [13  0  0]\n",
            " [19  0  1]\n",
            " [ 1  0  0]\n",
            " [ 6  0  0]\n",
            " [10  0  0]\n",
            " [12  0  0]\n",
            " [ 1  0  0]\n",
            " [ 1  0  0]\n",
            " [ 6  0  0]\n",
            " [13  0  0]\n",
            " [ 1  0  0]\n",
            " [11  0  0]\n",
            " [23  0  0]\n",
            " [ 2  0  0]\n",
            " [13  0  0]\n",
            " [ 1  0  0]\n",
            " [13  0  0]\n",
            " [25  0  0]\n",
            " [ 2  0  0]\n",
            " [ 1  0  0]\n",
            " [13  0  0]\n",
            " [ 2  0  1]\n",
            " [ 3  0  1]\n",
            " [30  0  0]\n",
            " [14  0  0]\n",
            " [ 6  0  0]\n",
            " [ 1  0  0]\n",
            " [ 1  0  0]\n",
            " [10  0  0]\n",
            " [ 1  0  0]\n",
            " [ 1  0  0]\n",
            " [12  0  0]\n",
            " [ 5  0  0]\n",
            " [ 1  0  0]\n",
            " [10  0  0]\n",
            " [16  0  0]\n",
            " [11  0  0]\n",
            " [13  0  0]\n",
            " [ 5  0  2]\n",
            " [12  0  0]\n",
            " [ 8  0  0]\n",
            " [ 3  0  0]\n",
            " [ 1  0  0]\n",
            " [ 7  0  0]\n",
            " [ 4  0  0]\n",
            " [ 7  0  0]\n",
            " [ 1  0  0]\n",
            " [ 5  0  0]\n",
            " [ 1  0  0]\n",
            " [ 2  0  0]\n",
            " [ 9  0  0]\n",
            " [ 1  0  0]\n",
            " [ 4  0  0]\n",
            " [ 2  0  0]\n",
            " [ 4  0  0]\n",
            " [ 3  0  0]\n",
            " [ 9  0  0]\n",
            " [ 1  0  0]\n",
            " [16  0  0]\n",
            " [13  0  0]\n",
            " [11  0  0]\n",
            " [ 1  0  0]\n",
            " [ 1  0  0]\n",
            " [ 2  0  0]\n",
            " [ 1  0  0]\n",
            " [10  0  0]\n",
            " [ 4  0  0]\n",
            " [ 2  0  0]\n",
            " [14  0  0]\n",
            " [ 1  0  0]]\n",
            "Mean Absolute Percentage Error (MAPE): 53.78%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
        "from torchvision.transforms import functional as F\n",
        "\n",
        "# Load the pre-trained Faster R-CNN model\n",
        "def load_model():\n",
        "    model = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Define the dataset class\n",
        "class MaskedFaceTestDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.root = root\n",
        "        self.imgs = sorted(glob.glob(os.path.join(root, '*.png')))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.imgs[index]\n",
        "        annotation_path = img_path.replace('.png', '.xml')\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        true_counts = self.parse_annotation(annotation_path)\n",
        "        return img, true_counts, img_path\n",
        "\n",
        "    def parse_annotation(self, annotation_path):\n",
        "        tree = ET.parse(annotation_path)\n",
        "        root = tree.getroot()\n",
        "        counts = np.zeros(3, dtype=int)  # [with_mask, without_mask, mask_weared_incorrect]\n",
        "        class_map = {'with_mask': 0, 'without_mask': 1, 'mask_weared_incorrect': 2}\n",
        "        for member in root.findall('object'):\n",
        "            class_name = member.find('name').text\n",
        "            if class_name in class_map:\n",
        "                class_id = class_map[class_name]\n",
        "                counts[class_id] += 1\n",
        "        return counts\n",
        "\n",
        "# Prediction function using the Faster R-CNN model\n",
        "def get_predictions_for_image(img, model):\n",
        "    transform = F.to_tensor\n",
        "    img_tensor = transform(img).unsqueeze_(0)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    img_tensor = img_tensor.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = model(img_tensor)\n",
        "\n",
        "    pred_classes = predictions[0]['labels'].cpu().numpy()\n",
        "    pred_scores = predictions[0]['scores'].cpu().numpy()\n",
        "    threshold = 0.8\n",
        "    filtered_predictions = [(pred_classes[i], pred_scores[i]) for i, score in enumerate(pred_scores) if score > threshold]\n",
        "\n",
        "    counts = np.zeros(3, dtype=int)\n",
        "    for cls, _ in filtered_predictions:\n",
        "        if cls in [1, 2, 3]:\n",
        "            counts[cls-1] += 1\n",
        "\n",
        "    return counts\n",
        "\n",
        "# Function to count masks and calculate MAPE\n",
        "def count_masks(dataset, model):\n",
        "    counts = []\n",
        "    mape_scores = []\n",
        "\n",
        "    for img, true_counts, img_path in dataset:\n",
        "        predicted_counts = get_predictions_for_image(img, model)\n",
        "\n",
        "        mape_score = np.mean([\n",
        "            np.abs(tc - pc) / max(tc, 1) for tc, pc in zip(true_counts, predicted_counts)\n",
        "        ]) * 100\n",
        "        counts.append(predicted_counts)\n",
        "        mape_scores.append(mape_score)\n",
        "\n",
        "    counts_array = np.array(counts)\n",
        "    mean_mape = np.mean(mape_scores)\n",
        "    return counts_array, mean_mape\n",
        "\n",
        "\n",
        "model = load_model()\n",
        "root_dir = \"/content/drive/MyDrive/val\"\n",
        "dataset = MaskedFaceTestDataset(root=root_dir)\n",
        "counts_array, mean_mape = count_masks(dataset, model)\n",
        "\n",
        "print(f\"Counts per class: {counts_array}\")\n",
        "print(f\"Mean Absolute Percentage Error (MAPE): {mean_mape:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SunpfDsPaM5O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}